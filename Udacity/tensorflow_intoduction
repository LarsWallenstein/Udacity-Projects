{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_intoduction","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1byDTyeLJqOB","colab_type":"code","outputId":"726b8b10-72ea-4e4b-f12b-48ecf261d809","executionInfo":{"status":"ok","timestamp":1562062124480,"user_tz":-180,"elapsed":562,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","\n","\n","hello_constant = tf.constant('Hello World!')#0-dimension string tensor\n","\n","with tf.Session() as sess:\n","  output = sess.run(hello_constant)\n","  print(output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["b'Hello World!'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t_FoLY3RKD49","colab_type":"code","colab":{}},"source":["# A is a 0-dimensional int32 tensor\n","A = tf.constant(1234) \n","# B is a 1-dimensional int32 tensor\n","B = tf.constant([123,456,789]) \n","# C is a 2-dimensional int32 tensor\n","C = tf.constant([ [123,456,789], [222,333,444] ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsYiXnlhKvNE","colab_type":"code","colab":{}},"source":["n_features = 120\n","n_labels = 5\n","weights = tf.Variable(tf.truncated_normal((n_features,n_labels)))\n","bias = tf.Variable(tf.zeros(n_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NFtXIcrMqa8","colab_type":"code","colab":{}},"source":["\n","import tensorflow as tf\n","\n","def get_weights(n_features, n_labels):\n","    \"\"\"\n","    Return TensorFlow weights\n","    :param n_features: Number of features\n","    :param n_labels: Number of labels\n","    :return: TensorFlow weights\n","    \"\"\"\n","    return tf.Variable(tf.truncated_normal((n_features,n_labels)))\n","\n","\n","def get_biases(n_labels):\n","    \"\"\"\n","    Return TensorFlow bias\n","    :param n_labels: Number of labels\n","    :return: TensorFlow bias\n","    \"\"\"\n","    return tf.Variable(tf.zeros(n_labels))\n","\n","\n","def linear(input, w, b):\n","    \"\"\"\n","    Return linear function in TensorFlow\n","    :param input: TensorFlow input\n","    :param w: TensorFlow weights\n","    :param b: TensorFlow biases\n","    :return: TensorFlow linear function\n","    \"\"\"\n","    return tf.matmul(input,w)+b"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfydz4-zQEXu","colab_type":"code","outputId":"425bee36-6b55-4f57-e433-0911cd5869cd","executionInfo":{"status":"ok","timestamp":1562063885132,"user_tz":-180,"elapsed":2603,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}},"colab":{"base_uri":"https://localhost:8080/","height":601}},"source":["# Solution is available in the other \"sandbox_solution.py\" tab\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","\n","def mnist_features_labels(n_labels):\n","    \"\"\"\n","    Gets the first <n> labels from the MNIST dataset\n","    :param n_labels: Number of labels to use\n","    :return: Tuple of feature list and label list\n","    \"\"\"\n","    mnist_features = []\n","    mnist_labels = []\n","\n","    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","    # In order to make quizzes run faster, we're only looking at 10000 images\n","    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n","\n","        # Add features and labels if it's for the first <n>th labels\n","        if mnist_label[:n_labels].any():\n","            mnist_features.append(mnist_feature)\n","            mnist_labels.append(mnist_label[:n_labels])\n","\n","    return mnist_features, mnist_labels\n","\n","\n","# Number of features (28*28 image is 784 features)\n","n_features = 784\n","# Number of labels\n","n_labels = 3\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32)\n","labels = tf.placeholder(tf.float32)\n","\n","# Weights and Biases\n","w = get_weights(n_features, n_labels)\n","b = get_biases(n_labels)\n","\n","# Linear Function xW + b\n","logits = linear(features, w, b)\n","\n","# Training data\n","train_features, train_labels = mnist_features_labels(n_labels)\n","\n","with tf.Session() as session:\n","    # TODO: Initialize session variables\n","    session.run(tf.global_variables_initializer())\n","    # Softmax\n","    prediction = tf.nn.softmax(logits)\n","\n","    # Cross entropy\n","    # This quantifies how far off the predictions were.\n","    # You'll learn more about this in future lessons.\n","    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n","\n","    # Training loss\n","    # You'll learn more about this in future lessons.\n","    loss = tf.reduce_mean(cross_entropy)\n","\n","    # Rate at which the weights are changed\n","    # You'll learn more about this in future lessons.\n","    learning_rate = 0.08\n","\n","    # Gradient Descent\n","    # This is the method used to train the model\n","    # You'll learn more about this in future lessons.\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n","\n","    # Run optimizer and get loss\n","    _, l = session.run(\n","        [optimizer, loss],\n","        feed_dict={features: train_features, labels: train_labels})\n","\n","# Print loss\n","print('Loss: {}'.format(l))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0702 10:38:03.232028 140534954317696 deprecation.py:323] From <ipython-input-9-a1e9bc5c590b>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","W0702 10:38:03.233386 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","W0702 10:38:03.234838 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","W0702 10:38:03.576932 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0702 10:38:03.948275 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","W0702 10:38:03.950925 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0702 10:38:04.219827 140534954317696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","Loss: 9.984528541564941\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cEpH-UuUQyDY","colab_type":"code","colab":{}},"source":["# Solution is available in the other \"solution.py\" tab\n","import tensorflow as tf\n","\n","\n","def run():\n","    output = None\n","    logit_data = [2.0, 1.0, 0.1]\n","    logits = tf.placeholder(tf.float32)\n","    \n","    # TODO: Calculate the softmax of the logits\n","    #logits = tf.exp(logit_data)/sum(tf.exp(logit_data))   \n","    softmax = tf.nn.softmax(logits)\n","    with tf.Session() as sess:\n","        # TODO: Feed in the logit data\n","        sess.run(tf.global_variables_initializer())\n","        # output = sess.run(softmax,    )\n","        output = sess.run(softmax,feed_dict={logits: logit_data})\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQcSRgzcSxbn","colab_type":"code","outputId":"5b1ecbe0-7c67-43a7-846b-6e4256c6c733","executionInfo":{"status":"ok","timestamp":1562064703744,"user_tz":-180,"elapsed":1037,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Solution is available in the other \"solution.py\" tab\n","import tensorflow as tf\n","\n","softmax_data = [0.7, 0.2, 0.1]\n","one_hot_data = [1.0, 0.0, 0.0]\n","\n","softmax = tf.placeholder(tf.float32)\n","one_hot = tf.placeholder(tf.float32)\n","\n","cross_entropy = -tf.reduce_sum(tf.multiply(one_hot_data,tf.log(softmax_data)))\n","\n","# TODO: Print cross entropy from session\n","with tf.Session() as sess:\n","  print(sess.run(cross_entropy,feed_dict={one_hot: one_hot_data,softmax: softmax_data}))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.35667497\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aMlTaCwST0Ju","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"66df62a7-6303-4410-a57a-12b7a9a3b985","executionInfo":{"status":"ok","timestamp":1562078644535,"user_tz":-180,"elapsed":1324,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TNr6yJZxI1Il","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PavAxMtZJGdG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8e175021-ba58-4129-a2df-a3d25b5aa08f","executionInfo":{"status":"ok","timestamp":1562078876379,"user_tz":-180,"elapsed":889,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["784*10*32/8"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31360.0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"X0usYM4UJzKP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"177150e5-07ff-4b3b-e7d0-39d42db1493d","executionInfo":{"status":"ok","timestamp":1562078988021,"user_tz":-180,"elapsed":811,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["172480000/1024**2"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["164.48974609375"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"9tdCXsKaKcOi","colab_type":"code","colab":{}},"source":["features = tf.placeholder(tf.float32, [None, n_input])#None - size of a mini-batch? if so? it would expect any size but zero"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtQxey7zLBsa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"62aff33e-b861-46ca-f20a-80544bef023f","executionInfo":{"status":"ok","timestamp":1562079190760,"user_tz":-180,"elapsed":761,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["50000/128."],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["390.625"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"961G-J9QLNvK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"788a1b44-4323-4ade-f26e-73d6fe684d7e","executionInfo":{"status":"ok","timestamp":1562079213508,"user_tz":-180,"elapsed":850,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["50000-390*128"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["80"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Z7qdowMvLTRQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108},"outputId":"84c682e1-1520-4e0e-b649-1fece710db7b","executionInfo":{"status":"ok","timestamp":1562080808302,"user_tz":-180,"elapsed":766,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["import math\n","def batches(batch_size, features, labels):\n","    \"\"\"\n","    Create batches of features and labels\n","    :param batch_size: The batch size\n","    :param features: List of features\n","    :param labels: List of labels\n","    :return: Batches of (Features, Labels)\n","    \"\"\"\n","    assert len(features) == len(labels)\n","    output_batches = []\n","    for start_i in range(0,len(features),batch_size):\n","      end_i = start_i+batch_size\n","      batch = [features[start_i:end_i],labels[start_i:end_i]]\n","      output_batches.append(batch)\n","    return output_batches\n","from pprint import pprint\n","\n","# 4 Samples of features\n","example_features = [\n","    ['F11','F12','F13','F14'],\n","    ['F21','F22','F23','F24'],\n","    ['F31','F32','F33','F34'],\n","    ['F41','F42','F43','F44']]\n","# 4 Samples of labels\n","example_labels = [\n","    ['L11','L12'],\n","    ['L21','L22'],\n","    ['L31','L32'],\n","    ['L41','L42']]\n","\n","# PPrint prints data structures like 2d arrays, so they are easier to read\n","pprint(batches(3, example_features, example_labels))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[[[['F11', 'F12', 'F13', 'F14'],\n","   ['F21', 'F22', 'F23', 'F24'],\n","   ['F31', 'F32', 'F33', 'F34']],\n","  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n"," [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qsM8FQLuQ_FD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108},"outputId":"fc34f221-58aa-48df-f2f1-ce184d61ea9f","executionInfo":{"status":"ok","timestamp":1562081366690,"user_tz":-180,"elapsed":25802,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["import math\n","def batches(batch_size, features, labels):\n","    \"\"\"\n","    Create batches of features and labels\n","    :param batch_size: The batch size\n","    :param features: List of features\n","    :param labels: List of labels\n","    :return: Batches of (Features, Labels)\n","    \"\"\"\n","    assert len(features) == len(labels)\n","    outout_batches = []\n","    \n","    sample_size = len(features)\n","    for start_i in range(0, sample_size, batch_size):\n","        end_i = start_i + batch_size\n","        batch = [features[start_i:end_i], labels[start_i:end_i]]\n","        outout_batches.append(batch)\n","        \n","    return outout_batches\n","\n","from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","import numpy as np\n","\n","learning_rate = 0.001\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))\n","\n","# Logits - xW + b\n","logits = tf.add(tf.matmul(features, weights), bias)\n","\n","# Define loss and optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","# Calculate accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","\n","# TODO: Set batch size\n","batch_size = 1\n","assert batch_size is not None, 'You must set the batch size'\n","\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","    \n","    # TODO: Train optimizer on all batches\n","    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n","      sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n","\n","    # Calculate accuracy for test dataset\n","    test_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: test_features, labels: test_labels})\n","\n","print('Test Accuracy: {}'.format(test_accuracy))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","Test Accuracy: 0.7493000030517578\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aaFO52J-SxF2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a3ee8092-f909-4520-8229-b05799d198f8","executionInfo":{"status":"ok","timestamp":1562082407507,"user_tz":-180,"elapsed":82755,"user":{"displayName":"Alex Korsakov","photoUrl":"","userId":"18248625518508782982"}}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","import numpy as np  # Helper function created in Mini-batching section\n","\n","\n","def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n","    \"\"\"\n","    Print cost and validation accuracy of an epoch\n","    \"\"\"\n","    current_cost = sess.run(\n","        cost,\n","        feed_dict={features: last_features, labels: last_labels})\n","    valid_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: valid_features, labels: valid_labels})\n","    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n","        epoch_i,\n","        current_cost,\n","        valid_accuracy))\n","\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","valid_features = mnist.validation.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","valid_labels = mnist.validation.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))\n","\n","# Logits - xW + b\n","logits = tf.add(tf.matmul(features, weights), bias)\n","\n","# Define loss and optimizer\n","learning_rate = tf.placeholder(tf.float32)\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","# Calculate accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","init = tf.global_variables_initializer()\n","\n","batch_size = 50\n","epochs = 100\n","learn_rate = 0.005\n","\n","train_batches = batches(batch_size, train_features, train_labels)\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    # Training cycle\n","    for epoch_i in range(epochs):\n","\n","        # Loop over all batches\n","        for batch_features, batch_labels in train_batches:\n","            train_feed_dict = {\n","                features: batch_features,\n","                labels: batch_labels,\n","                learning_rate: learn_rate}\n","            sess.run(optimizer, feed_dict=train_feed_dict)\n","\n","        # Print cost and validation accuracy of an epoch\n","        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n","\n","    # Calculate accuracy for test dataset\n","    test_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: test_features, labels: test_labels})\n","\n","print('Test Accuracy: {}'.format(test_accuracy))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","Epoch: 0    - Cost: 6.65     Valid Accuracy: 0.307\n","Epoch: 1    - Cost: 4.59     Valid Accuracy: 0.459\n","Epoch: 2    - Cost: 3.56     Valid Accuracy: 0.546\n","Epoch: 3    - Cost: 2.9      Valid Accuracy: 0.601\n","Epoch: 4    - Cost: 2.43     Valid Accuracy: 0.642\n","Epoch: 5    - Cost: 2.09     Valid Accuracy: 0.676\n","Epoch: 6    - Cost: 1.83     Valid Accuracy: 0.7  \n","Epoch: 7    - Cost: 1.64     Valid Accuracy: 0.717\n","Epoch: 8    - Cost: 1.49     Valid Accuracy: 0.73 \n","Epoch: 9    - Cost: 1.38     Valid Accuracy: 0.744\n","Epoch: 10   - Cost: 1.28     Valid Accuracy: 0.756\n","Epoch: 11   - Cost: 1.19     Valid Accuracy: 0.764\n","Epoch: 12   - Cost: 1.12     Valid Accuracy: 0.772\n","Epoch: 13   - Cost: 1.05     Valid Accuracy: 0.778\n","Epoch: 14   - Cost: 0.994    Valid Accuracy: 0.786\n","Epoch: 15   - Cost: 0.943    Valid Accuracy: 0.792\n","Epoch: 16   - Cost: 0.896    Valid Accuracy: 0.798\n","Epoch: 17   - Cost: 0.854    Valid Accuracy: 0.802\n","Epoch: 18   - Cost: 0.816    Valid Accuracy: 0.805\n","Epoch: 19   - Cost: 0.781    Valid Accuracy: 0.809\n","Epoch: 20   - Cost: 0.749    Valid Accuracy: 0.812\n","Epoch: 21   - Cost: 0.72     Valid Accuracy: 0.816\n","Epoch: 22   - Cost: 0.694    Valid Accuracy: 0.818\n","Epoch: 23   - Cost: 0.669    Valid Accuracy: 0.82 \n","Epoch: 24   - Cost: 0.646    Valid Accuracy: 0.823\n","Epoch: 25   - Cost: 0.626    Valid Accuracy: 0.825\n","Epoch: 26   - Cost: 0.606    Valid Accuracy: 0.828\n","Epoch: 27   - Cost: 0.588    Valid Accuracy: 0.829\n","Epoch: 28   - Cost: 0.571    Valid Accuracy: 0.832\n","Epoch: 29   - Cost: 0.556    Valid Accuracy: 0.835\n","Epoch: 30   - Cost: 0.541    Valid Accuracy: 0.837\n","Epoch: 31   - Cost: 0.528    Valid Accuracy: 0.837\n","Epoch: 32   - Cost: 0.515    Valid Accuracy: 0.839\n","Epoch: 33   - Cost: 0.503    Valid Accuracy: 0.841\n","Epoch: 34   - Cost: 0.492    Valid Accuracy: 0.842\n","Epoch: 35   - Cost: 0.481    Valid Accuracy: 0.844\n","Epoch: 36   - Cost: 0.472    Valid Accuracy: 0.844\n","Epoch: 37   - Cost: 0.462    Valid Accuracy: 0.845\n","Epoch: 38   - Cost: 0.454    Valid Accuracy: 0.846\n","Epoch: 39   - Cost: 0.445    Valid Accuracy: 0.847\n","Epoch: 40   - Cost: 0.438    Valid Accuracy: 0.848\n","Epoch: 41   - Cost: 0.43     Valid Accuracy: 0.849\n","Epoch: 42   - Cost: 0.423    Valid Accuracy: 0.851\n","Epoch: 43   - Cost: 0.417    Valid Accuracy: 0.851\n","Epoch: 44   - Cost: 0.411    Valid Accuracy: 0.852\n","Epoch: 45   - Cost: 0.405    Valid Accuracy: 0.853\n","Epoch: 46   - Cost: 0.399    Valid Accuracy: 0.854\n","Epoch: 47   - Cost: 0.394    Valid Accuracy: 0.855\n","Epoch: 48   - Cost: 0.389    Valid Accuracy: 0.857\n","Epoch: 49   - Cost: 0.384    Valid Accuracy: 0.858\n","Epoch: 50   - Cost: 0.379    Valid Accuracy: 0.859\n","Epoch: 51   - Cost: 0.375    Valid Accuracy: 0.859\n","Epoch: 52   - Cost: 0.371    Valid Accuracy: 0.859\n","Epoch: 53   - Cost: 0.367    Valid Accuracy: 0.86 \n","Epoch: 54   - Cost: 0.363    Valid Accuracy: 0.861\n","Epoch: 55   - Cost: 0.359    Valid Accuracy: 0.861\n","Epoch: 56   - Cost: 0.355    Valid Accuracy: 0.862\n","Epoch: 57   - Cost: 0.352    Valid Accuracy: 0.862\n","Epoch: 58   - Cost: 0.349    Valid Accuracy: 0.864\n","Epoch: 59   - Cost: 0.345    Valid Accuracy: 0.864\n","Epoch: 60   - Cost: 0.342    Valid Accuracy: 0.866\n","Epoch: 61   - Cost: 0.339    Valid Accuracy: 0.867\n","Epoch: 62   - Cost: 0.336    Valid Accuracy: 0.867\n","Epoch: 63   - Cost: 0.333    Valid Accuracy: 0.868\n","Epoch: 64   - Cost: 0.331    Valid Accuracy: 0.869\n","Epoch: 65   - Cost: 0.328    Valid Accuracy: 0.87 \n","Epoch: 66   - Cost: 0.325    Valid Accuracy: 0.87 \n","Epoch: 67   - Cost: 0.323    Valid Accuracy: 0.871\n","Epoch: 68   - Cost: 0.32     Valid Accuracy: 0.872\n","Epoch: 69   - Cost: 0.318    Valid Accuracy: 0.873\n","Epoch: 70   - Cost: 0.315    Valid Accuracy: 0.873\n","Epoch: 71   - Cost: 0.313    Valid Accuracy: 0.873\n","Epoch: 72   - Cost: 0.311    Valid Accuracy: 0.873\n","Epoch: 73   - Cost: 0.309    Valid Accuracy: 0.874\n","Epoch: 74   - Cost: 0.306    Valid Accuracy: 0.875\n","Epoch: 75   - Cost: 0.304    Valid Accuracy: 0.875\n","Epoch: 76   - Cost: 0.302    Valid Accuracy: 0.876\n","Epoch: 77   - Cost: 0.3      Valid Accuracy: 0.876\n","Epoch: 78   - Cost: 0.298    Valid Accuracy: 0.876\n","Epoch: 79   - Cost: 0.296    Valid Accuracy: 0.876\n","Epoch: 80   - Cost: 0.294    Valid Accuracy: 0.877\n","Epoch: 81   - Cost: 0.292    Valid Accuracy: 0.878\n","Epoch: 82   - Cost: 0.29     Valid Accuracy: 0.878\n","Epoch: 83   - Cost: 0.289    Valid Accuracy: 0.878\n","Epoch: 84   - Cost: 0.287    Valid Accuracy: 0.879\n","Epoch: 85   - Cost: 0.285    Valid Accuracy: 0.879\n","Epoch: 86   - Cost: 0.283    Valid Accuracy: 0.88 \n","Epoch: 87   - Cost: 0.282    Valid Accuracy: 0.88 \n","Epoch: 88   - Cost: 0.28     Valid Accuracy: 0.881\n","Epoch: 89   - Cost: 0.278    Valid Accuracy: 0.881\n","Epoch: 90   - Cost: 0.277    Valid Accuracy: 0.881\n","Epoch: 91   - Cost: 0.275    Valid Accuracy: 0.882\n","Epoch: 92   - Cost: 0.273    Valid Accuracy: 0.882\n","Epoch: 93   - Cost: 0.272    Valid Accuracy: 0.882\n","Epoch: 94   - Cost: 0.27     Valid Accuracy: 0.882\n","Epoch: 95   - Cost: 0.269    Valid Accuracy: 0.882\n","Epoch: 96   - Cost: 0.267    Valid Accuracy: 0.883\n","Epoch: 97   - Cost: 0.266    Valid Accuracy: 0.883\n","Epoch: 98   - Cost: 0.264    Valid Accuracy: 0.884\n","Epoch: 99   - Cost: 0.263    Valid Accuracy: 0.884\n","Test Accuracy: 0.8794999718666077\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v2skg9VVVicV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}